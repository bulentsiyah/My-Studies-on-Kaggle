{"cells":[{"metadata":{"_uuid":"deb402ecd8ee331e196057cde31a28a7ab53e0e0"},"cell_type":"markdown","source":"[Kaan Can Yılmaz'ın](https://www.udemy.com/user/kaan-can-yilmaz/)\n\n* [Machine Learning ve Python: A'dan Z'ye Makine Öğrenmesi](https://www.udemy.com/machine-learning-ve-python-adan-zye-makine-ogrenmesi-4)\n\nkursundan öğrendiklerimi denediğim ve derlediğim kernelimdir."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Loading and Preprocessing Data\n\n# Importing the training set\ndataset_train = pd.read_csv('../input/traininggoogleprices/TrainPrices.csv')\ndataset_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11059370b6b75724517fc18fb1929b4f1ccfbfac"},"cell_type":"code","source":"train = dataset_train.loc[:, [\"Open\"]].values\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d2211e41dd2e79012a685e83714d6426ad98007"},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = scaler.fit_transform(train)\ntrain_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f09093c184350e568620083c46117a6d4452b0f"},"cell_type":"code","source":"plt.plot(train_scaled)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80fa3372e2259c2acf8b0ec36bb968211b356061"},"cell_type":"code","source":"# Creating a data structure with 50 timesteps and 1 output\nX_train = []\ny_train = []\ntimesteps = 50\nfor i in range(timesteps, 1258):\n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6391ab93a10427ad253a5e5240b71c9725c9add"},"cell_type":"code","source":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train[0:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccf3ffab8b7594e7b9c32983e3068b53a40772dd"},"cell_type":"code","source":"y_train[0:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31528fa2b878cfde9c12733e2ce415fdcd2ea30c"},"cell_type":"code","source":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['accuracy'])\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 10, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea7a0617f04420192cc6da7b6bc7e70c8e9a20f1"},"cell_type":"code","source":"# Getting the real stock price of 2017\ndataset_test = pd.read_csv('../input/google-stock-price/Stock_Price_Test.csv')\ndataset_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"902563110c842a4db96973fbd6b37df7f3e159c5"},"cell_type":"code","source":"real_stock_price = dataset_test.loc[:, [\"Open\"]].values\nreal_stock_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5cf4df11ea44b8436832dd8eb0681cb873216aa"},"cell_type":"code","source":"# Getting the predicted stock price of 2017\ndataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\n#inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ab2eab2150fdc18119da729810021f315a02aa1"},"cell_type":"code","source":"X_test = []\nfor i in range(timesteps, 70):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd72ac0819e564991cda315ba746e55e7c9663bc"},"cell_type":"markdown","source":"**Long Short Term Memory (LSTMs)**"},{"metadata":{"trusted":true,"_uuid":"7fdd95cd3de51f0010737da9cd7426388514fc88"},"cell_type":"code","source":"import numpy\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c912c336bca59f5e887e3d51037767dac0cc23a"},"cell_type":"code","source":"data = pd.read_csv('../input/airline-passengers/international-airline-passengers.csv',skipfooter=5)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c01b9c34266a11c7dda53336a05f8f2a3ddcbb"},"cell_type":"code","source":"dataset = data.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel(\"time\")\nplt.ylabel(\"Number of Passenger\")\nplt.title(\"international airline passenger\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"423b3f53bf721aabb83981c2c24d58b1bd871fb6"},"cell_type":"code","source":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f72df48cba3df6f27f9e0711cc2f73037b3ec768"},"cell_type":"code","source":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84fc12a2fcbdb74af1dfb19e5dea890a72f1a1c1"},"cell_type":"code","source":"train_size = int(len(dataset) * 0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9142acfdf5edf0704cc570e8d43236b4602671a0"},"cell_type":"code","source":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c558a2a893936601b9ba20a461e95aa258423f6d"},"cell_type":"code","source":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ee876daab48411f87a154182676be655e2e0950"},"cell_type":"code","source":"trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63bf5e7c0258878cf0d2e0be062a4a0ab3993112"},"cell_type":"code","source":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82c94da5482122c6faf27b4a0700f769d2d25aac"},"cell_type":"code","source":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e3fb4b339e6b3c45de4db94ba1aa9f81fce5a65"},"cell_type":"code","source":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}