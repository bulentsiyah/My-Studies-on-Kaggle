{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nfrom keras.regularizers import l1\nfrom keras import backend as K\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport csv\nimport re\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, BatchNormalization, Dropout\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\n\n# ignore Deprecation Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport os\n\ntrain_orj = pd.read_csv(\"../input/train.csv\", header=0)\ntest_orj = pd.read_csv(\"../input/test.csv\", header=0)\ntrain_orj.head()\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_orj.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facfa03728a1b6f9022048d24900fb877419c784"},"cell_type":"code","source":"def preprocess(data):\n    \n    #Kabin\n    data.Cabin.fillna('9', inplace=True)\n    #data['Cabin'].replace('0', 9, inplace=True)\n    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n    data = data.drop([\"Cabin\"],axis=1)\n\n    # Cinsiyeti tam sayıya çevirelim\n    data['Sex'].replace('female', 1, inplace=True)\n    data['Sex'].replace('male', 2, inplace=True)\n    \n    # Gemiye biniş limanlarını tam sayıya çevirelim\n    data['Embarked'].replace('S', 1, inplace=True)\n    data['Embarked'].replace('C', 2, inplace=True)\n    data['Embarked'].replace('Q', 3, inplace=True)\n    \n    # Olmayan (NA) yaş değerlerini medyan ile dolduralım\n    data['Age'].fillna(data['Age'].median(), inplace=True)\n    #data['Age'] = [0 if each >= 60 else 1 if each >= 35 else 2 if each >= 18 else 3 if each >= 12 else 4 if each >= 5 else 5 for each in data['Age']]\n   \n    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n    data['Embarked'].fillna(data['Embarked'].median(), inplace=True)\n    \n    data = data.drop([\"Ticket\"],axis=1)\n    data = data.drop([\"Fare\"],axis=1)\n    data['SibSp'].replace(0, 9, inplace=True)\n    data['Parch'].replace(0, 9, inplace=True)\n    return data\n\ndef group_titles(data):\n    #data['Names'] = data['Name'].map(lambda x: len(re.split(' ', x)))\n    data['Title'] = data['Name'].map(lambda x: re.search(', (.+?) ', x).group(1))\n    data['Title'].replace('Master.', 1, inplace=True)\n    data['Title'].replace('Mr.', 2, inplace=True)\n    data['Title'].replace(['Ms.','Mlle.', 'Miss.'], 3, inplace=True)\n    data['Title'].replace(['Mme.', 'Mrs.'], 4, inplace=True)\n    data['Title'].replace(['Dona.', 'Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'the'], 5, inplace=True)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d05c1efea8ba5e4e3008d395df3a3abed3ad572a"},"cell_type":"code","source":"train = train_orj.copy().drop([\"PassengerId\"],axis=1)\ntrain=preprocess(train)\ntrain=group_titles(train)\ntrain = train.drop([\"Name\"],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a29acfbda9afd7569858a496b42b841f73f2510"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"499a867e84b4afc5b6e7f94d238ef3193d5bdc24"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(train.Age, palette=\"icefire\")\n#train.Age.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"299a4f206b1dba1e38edd31e9f67d87cd2a1bd5b"},"cell_type":"code","source":"x = train.iloc[:,1:train.shape[1]].values #bağımsız değişkenler\ny = train.Survived.values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)\n\n\n#Y_train=np.array(Y_train).astype(int)\n#X_train=np.array(X_train).astype(float)\n#Y_val = np.array(Y_val).astype(int)\n#X_val = np.array(X_val).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8981e7fcb315c6aece7948257d5d804ed9a42995"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Number of Survived classes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"760749aad03ad34562ba669eab9f2c8c961ef50e"},"cell_type":"code","source":"#model 1\n'''\nnum_epochs = 200\nbatch_size = 32\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=input_length-1, activation='softplus'))\nmodel.add(Dense(32, activation='softplus'))\nmodel.add(Dense(16, activation='softplus'))  \nmodel.add(Dense(8, activation='softplus')) \nmodel.add(Dense(1, activation='softplus'))\n\nlr = .001\nadam0 = Adam(lr = lr)\n\n# Modeli derleyip ve daha iyi bir sonuç elde edildiğinde ağırlıkları kaydedelim\nmodel.compile(loss='binary_crossentropy', optimizer=adam0, metrics=['accuracy'])\nfilepath = 'weights.best.hdf5'\ncheckpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory_model = model.fit(X_train, Y_train, callbacks=callbacks_list, epochs=num_epochs, batch_size=batch_size, verbose=0)\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e943c35d044c8e76eb83baad9b7b420f383a1333","scrolled":false},"cell_type":"code","source":"# model 2\nmodel = Sequential()\n\n# layers\nmodel.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Train the ANN\nhistory = model.fit(X_train, Y_train, batch_size = 32, epochs = 300, validation_data = (X_val,Y_val))\n\nscores = model.evaluate(X_train, Y_train, verbose=0)\nprint(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"487c5432ed4a6ef8f5e2583e1a93423716e6350f"},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6be620cee72b5b9f411c0daa3ab4dadbe58f223"},"cell_type":"code","source":"# confusion matrix\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n# Predict the values from the validation dataset\ny_pred = model.predict(X_val)\ny_final = (y_pred > 0.5).astype(int).reshape(X_val.shape[0])\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_val, y_final) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eced493bb8226d199354caefee1bb69e15e8bc28"},"cell_type":"code","source":"# model 3\n'''\nfrom keras.layers import Input\nimport keras\nfrom keras.models import Model\n\ndef DenseNet(X_train):\n    ip = Input(shape=(X_train.shape[1],))\n    x_list = [ip]\n    \n    x = Dense(128, use_bias=False)(ip)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(128, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(64, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(64, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(32, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(32, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(16, use_bias=False)(x)    \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x_list.append(x)\n    x = keras.layers.concatenate(x_list)    \n    x = Dense(16, use_bias=False)(ip)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)    \n    \n    op = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=ip, outputs=op)\n    adam = Adam(lr=0.05,)\n    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n    return model\n\nmodel = DenseNet(X_train)\nhistory_model=model.fit(X_train, Y_train, epochs=32, batch_size=200, verbose=0,\n          validation_split=0.1)\nscores = model.evaluate(X_train, Y_train, verbose=0)\nprint(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"417caaedebc5cd53925d6b69a0639a2db2c91364"},"cell_type":"code","source":"test = test_orj.copy()\ntest=preprocess(test)\ntest=group_titles(test)\ntest = test.drop([\"Name\"],axis=1)\ntest.head()\n#print(test.Title.value_counts())\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"959d59cae62b742c04c82b04530de86acc96ea67"},"cell_type":"code","source":"sns.countplot(test.Age, palette=\"icefire\")\n#train.Age.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"816ff32b1086e438cd245d46c927bd81346eadfc"},"cell_type":"code","source":"test_ids = test.iloc[:,0].values #test_orj['PassengerId'].copy()\ntestdata = test.iloc[:,1:test.shape[1]].values #bağımsız değişkenler\nX_test =testdata # np.array(testdata).astype(float)\n\n#print(len(X_test))\n#print(X_test[0])\n\ny_pred = model.predict(X_test)\ny_final = (y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n#print(len(y_final))\noutput = pd.DataFrame({'PassengerId': test_orj['PassengerId'], 'Survived': y_final})\noutput.to_csv('prediction-ann_0150.csv', index=False)\n\nplt.figure(figsize=(10,5))\nsns.countplot(y_final, palette=\"icefire\")\nplt.title(\"(Test data) Number of Survived classes\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}